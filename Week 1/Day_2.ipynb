{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06e85608-610d-4c6d-8100-a10a83778a61",
   "metadata": {},
   "source": [
    "# Generative AI Day 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12397fd-c1e9-467e-a9fb-4d68747fbf4b",
   "metadata": {},
   "source": [
    "## Direct Inference using Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b093c8-4ae5-4421-9bf0-404d2fb415f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2a2f1d-138a-4799-9448-14ee8aa6fca6",
   "metadata": {},
   "source": [
    "### Define constants related to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e446fe01-53dd-46e9-b5bf-bf25dd399582",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5804736-c4a2-4405-b67e-c3e5994229dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9522e956-bd7e-4a7b-80ea-7a181ebd5a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload={\n",
    "    \"model\": MODEL,\n",
    "    \"messages\": messages,\n",
    "    \"stream\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5881e076-c3fc-453a-8ff5-7eb387dcb143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure model is loaded\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5669e7-316d-4f6a-911c-b7fba89ebaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(OLLAMA_API, headers=HEADERS, json=payload)\n",
    "print(Markdown(response.json()[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f155d7b-2a16-4cbe-a29e-1c273d9a1b80",
   "metadata": {},
   "source": [
    "## Introduction to Ollama package\n",
    "\n",
    "now we will do same thing but instead of maikng a direct HTTP call we will use elegant ollama python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcb523d-ee46-41e5-855d-24b5a4aa54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f8f9da-0dd6-4ca4-986c-f14b41e02207",
   "metadata": {},
   "source": [
    "### Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7cad5b-e246-40b8-a50a-461f06a5ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de9c1ac-10c8-4dd8-bbf1-a09ae9f89fae",
   "metadata": {},
   "source": [
    "## Now lets complete the same exercise of text summarization using `ollama`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b2d5a-5529-4c02-9130-28b8233d80b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "            Create this website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(self.url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevent in soup.body(['img', 'style', 'script', 'input']):\n",
    "            irrelevent.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f53737-3835-4295-a079-42c35e9a92b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pmo = Website(\"https://www.pmindia.gov.in/en/message-from-the-prime-minister/\")\n",
    "print(pmo.title)\n",
    "print(pmo.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b329ab-a9cd-4558-a293-ac26c6c71c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a96bb96-42eb-4771-bf89-123ff036994f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at website titled {website.title}\\n\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373c956d-edeb-4594-896a-da83dbe64b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5874af-6aa7-4073-af8e-b6b256a8f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for(pmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8adc1982-c064-4d48-a402-a53f1dda00d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize_openai(url):\n",
    "    website = Website(url)\n",
    "    ollama_via_openai = OpenAI(base_url=\"http://localhost:11434/v1\", api_key=\"ollama\")\n",
    "    response = ollama_via_openai.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages_for(website)\n",
    "    )\n",
    "    display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfe90a2-0652-4931-ab4d-5d9b10bd3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "summerize_openai(\"https://www.pmindia.gov.in/en/message-from-the-prime-minister/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb980c8d-52e9-4e0a-bd84-3af3a54d99ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summerize_ollama(url):\n",
    "    website = Website(url)\n",
    "    response = ollama.chat(model=MODEL, messages=messages_for(website))\n",
    "    display(Markdown(response[\"message\"][\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844bdb0-f6ab-4d83-aee7-43f3e23f163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summerize_ollama(\"https://www.pmindia.gov.in/en/message-from-the-prime-minister/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
